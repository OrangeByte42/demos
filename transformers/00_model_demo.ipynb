{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2818ba7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: ALL_PROXY=http://127.0.0.1:7890\n",
      "env: HTTP_PROXY=http://127.0.0.1:7890\n",
      "env: HTTPS_PROXY=http://127.0.0.1:7890\n"
     ]
    }
   ],
   "source": [
    "%env ALL_PROXY=http://127.0.0.1:7890\n",
    "%env HTTP_PROXY=http://127.0.0.1:7890\n",
    "%env HTTPS_PROXY=http://127.0.0.1:7890"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10fad987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_HUB_CACHE=./data/hf_cache\n"
     ]
    }
   ],
   "source": [
    "%env HF_HUB_CACHE=./data/hf_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9f074b",
   "metadata": {},
   "source": [
    "# Model's loading and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55ba3683",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee4fdb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from remote huggingface hub\n",
    "# model = AutoModel.from_pretrained('hfl/rbt3', force_download=True)\n",
    "model = AutoModel.from_pretrained('hfl/rbt3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1656132",
   "metadata": {},
   "source": [
    "# Model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5eec911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"directionality\": \"bidi\",\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 3,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pooler_fc_size\": 768,\n",
       "  \"pooler_num_attention_heads\": 12,\n",
       "  \"pooler_num_fc_layers\": 3,\n",
       "  \"pooler_size_per_head\": 128,\n",
       "  \"pooler_type\": \"first_token_transform\",\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.55.4\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 21128\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26499e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.output_attentions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f84c057",
   "metadata": {},
   "source": [
    "# Model Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdb17049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 8228, 8815, 8549, 9059, 8228, 8815,  117, 8554, 8310,  143,  159,\n",
       "         8803, 8415, 8410,  119,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"To be or not to be, this is a question.\"\n",
    "tokenizer = AutoTokenizer.from_pretrained('hfl/rbt3')\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ddbe72",
   "metadata": {},
   "source": [
    "## Model calling without model head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b94caaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.2716,  0.7016,  0.6917,  ...,  0.3925, -0.2240,  0.1228],\n",
       "         [ 0.1449, -0.1513, -0.1926,  ...,  0.3435, -0.2401,  0.0578],\n",
       "         [-0.1747, -0.5307, -0.2688,  ...,  0.2098, -0.3400,  0.1970],\n",
       "         ...,\n",
       "         [ 0.4631,  0.3436,  0.3143,  ..., -0.2536,  0.1682, -0.1007],\n",
       "         [ 0.0690,  0.0835, -0.4554,  ..., -0.8562, -0.2078,  0.1907],\n",
       "         [ 0.2686,  0.7054,  0.6892,  ...,  0.3950, -0.2225,  0.1240]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 3.1781e-01, -9.9970e-01, -9.9999e-01, -7.6409e-01,  9.9950e-01,\n",
       "          1.2464e-02,  4.4802e-02, -8.4214e-03,  9.9128e-01,  9.9588e-01,\n",
       "          1.4203e-01, -1.0000e+00,  1.8639e-01,  9.9819e-01, -9.9992e-01,\n",
       "          9.9524e-01,  9.9012e-01,  9.0738e-01, -9.5278e-01,  1.0680e-01,\n",
       "         -9.6405e-01, -9.9079e-01,  1.8284e-01,  8.4984e-01,  8.8799e-01,\n",
       "         -9.9560e-01, -9.9996e-01,  1.1651e-01, -9.7065e-01, -9.9983e-01,\n",
       "         -9.9072e-01, -9.9915e-01,  3.7124e-01,  5.0311e-01,  9.8902e-01,\n",
       "         -9.9441e-01,  8.7457e-02, -9.0737e-01, -9.9927e-01, -9.9148e-01,\n",
       "         -4.1260e-01,  9.5273e-01, -9.3426e-02,  9.9915e-01, -2.9414e-01,\n",
       "          3.2286e-01,  9.9962e-01,  4.9375e-01, -7.2415e-02,  6.2462e-01,\n",
       "         -6.3914e-02, -1.9549e-01, -9.6609e-01,  9.9659e-01, -2.9137e-01,\n",
       "          2.8217e-02,  9.9991e-01, -1.0000e+00, -9.9751e-01,  9.9683e-01,\n",
       "         -9.9586e-01,  9.7227e-01,  9.9947e-01,  8.6742e-01, -9.3914e-01,\n",
       "          9.9999e-01,  9.9944e-01,  9.4292e-01, -3.2369e-01, -9.9998e-01,\n",
       "          9.4130e-01,  4.4881e-01, -9.7460e-01, -1.4643e-01,  1.7312e-01,\n",
       "         -9.9924e-01,  9.9720e-01,  2.3385e-02,  9.9811e-01,  1.6960e-01,\n",
       "         -9.9899e-01, -7.5120e-03,  5.1371e-02,  6.2697e-02,  9.9918e-01,\n",
       "          9.9944e-01,  7.0809e-02, -9.8711e-01, -2.3783e-01, -9.9128e-01,\n",
       "         -4.9371e-01,  9.9880e-01,  9.9904e-01, -9.9949e-01,  9.9957e-01,\n",
       "         -7.5963e-01,  3.4329e-01, -1.1135e-02, -9.9307e-01,  9.9933e-01,\n",
       "         -1.9199e-02, -4.0468e-02,  1.0000e+00,  9.9813e-01, -3.7463e-01,\n",
       "         -9.9892e-01, -9.8566e-01,  9.9592e-01, -9.3153e-01,  1.0580e-01,\n",
       "          9.9960e-01,  9.9219e-01,  1.0000e+00,  9.9746e-01,  9.9968e-01,\n",
       "         -9.9995e-01, -3.2256e-01, -1.4869e-01, -9.8877e-01,  9.9674e-01,\n",
       "         -9.9312e-01,  8.6076e-01, -9.6502e-01, -2.4453e-01,  8.9016e-03,\n",
       "         -9.9933e-01,  4.1440e-01,  9.0227e-02, -9.9188e-01, -9.7745e-01,\n",
       "         -9.9746e-01, -9.9982e-01,  9.9317e-01,  2.3962e-02,  8.4763e-01,\n",
       "         -3.9901e-01,  4.6350e-01,  1.0176e-04, -9.9862e-01, -9.9999e-01,\n",
       "         -9.9988e-01,  3.9345e-01, -2.1356e-01,  9.9843e-01, -9.9821e-01,\n",
       "          9.8892e-01, -9.9956e-01,  9.9991e-01,  9.0653e-01, -2.7365e-02,\n",
       "          1.2502e-01,  4.9994e-01, -9.9939e-01, -1.6133e-02,  1.1420e-01,\n",
       "          9.7995e-01,  9.7659e-01,  9.9634e-01, -3.7171e-01,  9.9981e-01,\n",
       "         -9.3033e-01,  9.5451e-01,  1.0370e-01,  9.5510e-01,  9.9999e-01,\n",
       "         -9.9941e-01,  9.5183e-02, -9.9989e-01, -1.0729e-01,  1.9320e-01,\n",
       "          9.9882e-01,  9.9814e-01,  9.1935e-01,  9.9857e-01,  5.8684e-02,\n",
       "         -9.9972e-01,  8.1849e-01, -9.9869e-01,  5.4306e-01,  1.0000e+00,\n",
       "         -6.7347e-02,  6.7979e-01,  1.0000e+00, -8.5787e-01,  9.9274e-01,\n",
       "          3.8363e-02, -3.5680e-01, -9.4058e-01,  1.6849e-01,  9.0038e-01,\n",
       "          9.8424e-01, -9.3291e-01, -2.4258e-01,  9.8107e-01,  3.8565e-01,\n",
       "         -1.9632e-01, -9.9882e-01, -9.9988e-01,  9.9956e-01,  9.9962e-01,\n",
       "          5.5919e-01, -1.7685e-01,  9.9999e-01, -6.9563e-01,  9.9355e-01,\n",
       "         -2.0367e-01, -4.5197e-01, -2.0510e-01,  9.6783e-01,  6.4442e-02,\n",
       "          8.5692e-01,  1.6034e-03,  9.9959e-01, -8.8329e-01, -9.9994e-01,\n",
       "         -1.7945e-02,  9.7186e-01, -7.1498e-02, -9.5432e-01,  8.0427e-01,\n",
       "         -4.5080e-01,  9.9996e-01, -2.7395e-02, -2.3951e-01,  9.0335e-01,\n",
       "         -9.9746e-01,  8.4041e-01, -9.9984e-01, -9.9952e-01,  9.9827e-01,\n",
       "         -2.1390e-01, -1.0000e+00,  9.2914e-01,  9.9990e-01, -2.8789e-01,\n",
       "          9.1265e-01,  7.4521e-02, -9.9651e-01, -9.3027e-02, -1.4231e-01,\n",
       "         -9.9999e-01, -9.8576e-01, -9.9999e-01, -9.7252e-01, -4.8502e-02,\n",
       "          9.9547e-01, -9.9972e-01,  1.4077e-01, -9.9944e-01,  8.2996e-01,\n",
       "          9.9892e-01,  1.6671e-01, -2.9100e-01,  9.9995e-01, -9.7626e-01,\n",
       "          1.7700e-02, -4.9275e-01,  2.3812e-01, -6.4418e-02,  9.8568e-01,\n",
       "         -4.2000e-02,  9.9856e-01, -9.9916e-01,  1.3500e-01,  7.3151e-01,\n",
       "         -9.9872e-01, -6.6001e-01,  3.9596e-01, -1.4535e-01, -1.3305e-01,\n",
       "         -1.7516e-01,  3.4003e-02,  9.4091e-01,  9.9954e-01,  9.9999e-01,\n",
       "          9.9931e-01,  9.9962e-01,  9.9994e-01, -1.8542e-01, -8.8410e-01,\n",
       "         -9.9135e-01,  2.6203e-01, -9.9999e-01, -9.4845e-01, -9.9953e-01,\n",
       "          8.2071e-01,  1.3593e-01,  1.0000e+00, -9.9995e-01,  9.9995e-01,\n",
       "         -9.9441e-01, -1.9854e-01, -2.0825e-01,  1.8114e-01,  3.0714e-02,\n",
       "          3.0955e-01,  9.7559e-01,  4.2674e-01,  9.9638e-01,  9.8677e-01,\n",
       "          6.4753e-02, -1.5894e-01, -1.8237e-01,  2.6792e-01,  9.9676e-01,\n",
       "         -9.1407e-01,  9.6920e-01,  2.2524e-01,  9.9698e-01,  5.4671e-02,\n",
       "         -9.9942e-01,  9.9750e-01, -9.9842e-01,  3.1622e-03, -9.9953e-01,\n",
       "         -9.2786e-01,  2.4085e-01, -9.9948e-01,  7.5136e-02,  7.5968e-01,\n",
       "         -1.2807e-01, -2.3669e-01, -9.9996e-01, -9.8458e-01,  9.7879e-01,\n",
       "          9.9987e-01, -9.9995e-01,  9.9749e-01,  8.0689e-01, -9.0661e-01,\n",
       "          3.9266e-01,  5.9167e-01, -9.9978e-01,  9.9858e-01, -9.9974e-01,\n",
       "         -3.1820e-02,  9.9729e-01,  1.9127e-01, -9.9910e-01, -6.7709e-01,\n",
       "         -1.1396e-01,  9.1996e-01, -2.3128e-04,  9.9999e-01, -2.2408e-01,\n",
       "          9.1745e-03, -9.9768e-01, -9.8629e-01, -2.1034e-01,  9.3012e-02,\n",
       "          9.9999e-01, -9.9981e-01, -8.9722e-01,  9.9886e-01, -9.9998e-01,\n",
       "          2.7178e-01,  1.1048e-01,  4.7908e-04,  3.9873e-01, -9.6498e-01,\n",
       "         -9.9998e-01, -9.9839e-01,  9.9986e-01, -1.2385e-01, -9.8581e-02,\n",
       "          9.9466e-01,  9.9041e-01,  9.9922e-01, -9.8674e-01,  1.0982e-01,\n",
       "          9.9966e-01,  2.1804e-01,  1.4717e-01, -5.6544e-01, -7.2445e-01,\n",
       "         -9.4001e-01, -8.9474e-01, -4.7174e-02,  1.8651e-02,  5.5012e-03,\n",
       "         -9.9417e-01,  9.9925e-01,  9.9995e-01,  1.0000e+00, -1.9017e-01,\n",
       "         -9.7119e-01,  9.5935e-01, -7.4568e-01, -9.9889e-01, -1.1713e-01,\n",
       "          9.9978e-01, -9.8675e-01,  5.3089e-01, -7.6533e-01, -8.2536e-01,\n",
       "          9.9905e-01, -9.9915e-01,  8.8991e-02, -9.9999e-01, -9.9933e-01,\n",
       "         -1.0000e+00,  9.9873e-01,  4.9329e-03,  9.9323e-02, -9.8413e-01,\n",
       "          1.0000e+00,  9.7414e-01, -5.6355e-01,  2.9922e-02,  9.9989e-01,\n",
       "          3.0014e-02, -8.0442e-01, -9.9979e-01, -9.9252e-01,  9.7943e-01,\n",
       "         -2.6251e-01,  9.9999e-01, -5.5481e-01, -9.9873e-01,  4.7009e-01,\n",
       "          9.8073e-01, -1.0843e-01, -9.8525e-01, -9.6829e-01,  5.4128e-01,\n",
       "          2.5445e-02, -2.6076e-02, -3.7977e-01, -1.4825e-01,  9.9998e-01,\n",
       "         -2.6842e-01,  2.0875e-01, -4.5703e-02,  9.9994e-01,  7.4923e-01,\n",
       "         -9.9739e-01, -8.5102e-01, -5.8941e-03, -9.9127e-01, -9.9389e-01,\n",
       "         -9.6550e-01, -2.3144e-01, -4.4465e-01,  7.7482e-02, -9.9617e-01,\n",
       "         -9.9640e-01, -9.9997e-01, -1.1495e-02, -8.3903e-01, -8.8441e-01,\n",
       "          9.1939e-02, -9.9978e-01, -9.7086e-01,  9.9151e-01, -9.9723e-01,\n",
       "         -1.3548e-02,  9.6135e-01,  9.9867e-01, -9.9942e-01,  2.4958e-01,\n",
       "          9.6031e-01, -9.5529e-01, -2.4208e-01, -9.6603e-01,  2.2413e-01,\n",
       "         -9.6380e-01, -9.9987e-01, -1.8325e-01,  9.9929e-01,  9.9400e-01,\n",
       "          9.1291e-01,  9.9339e-01, -3.9785e-01,  9.4664e-01,  9.9763e-01,\n",
       "          9.9995e-01, -2.6731e-01, -1.9170e-01, -9.9994e-01,  8.7627e-01,\n",
       "          3.3202e-01,  3.7197e-01,  8.7628e-01, -9.9976e-01,  1.1190e-01,\n",
       "          1.7828e-01,  4.0808e-01,  9.9999e-01,  9.4040e-01,  4.9748e-02,\n",
       "         -9.9958e-01,  2.6785e-01, -3.9739e-01, -3.2214e-02, -9.9270e-01,\n",
       "          2.3000e-01,  9.9997e-01, -9.7210e-01,  1.3273e-01, -9.9976e-01,\n",
       "         -9.9949e-01,  9.9611e-01, -9.9965e-01,  9.9992e-01,  9.9760e-01,\n",
       "         -9.2184e-01, -9.9266e-02, -9.6145e-01,  2.5626e-01, -5.5298e-02,\n",
       "          3.7752e-02,  4.9037e-01,  2.2811e-01, -9.9994e-01,  5.0052e-01,\n",
       "          9.9928e-01,  3.6040e-02, -9.8866e-01, -9.9491e-01, -2.7741e-02,\n",
       "          9.9491e-01, -9.9013e-01, -9.9979e-01, -3.9153e-01, -2.2545e-01,\n",
       "         -1.0433e-01,  6.4410e-01,  1.8079e-01, -6.1749e-02, -9.9940e-01,\n",
       "         -3.5115e-02,  9.8942e-01, -7.9606e-01,  8.4697e-01, -9.5315e-01,\n",
       "         -8.1833e-01, -4.1840e-01,  9.9342e-01,  9.9960e-01, -9.9656e-01,\n",
       "         -9.9588e-01, -7.8263e-01,  1.2188e-02, -6.5713e-01,  9.9294e-01,\n",
       "         -3.1080e-01, -9.9012e-01,  1.6241e-01, -3.7023e-02, -2.6052e-01,\n",
       "         -9.2472e-01,  9.9996e-01, -9.9907e-01,  9.9999e-01, -9.9987e-01,\n",
       "         -9.9726e-01,  8.5820e-02,  9.9980e-01, -9.9994e-01,  9.1029e-02,\n",
       "          9.9062e-01, -9.9991e-01, -1.3246e-01, -8.9357e-01,  7.7193e-01,\n",
       "         -3.5409e-02, -8.1469e-02,  9.6979e-01, -9.9965e-01,  5.8888e-02,\n",
       "         -9.7342e-01,  7.7382e-01,  9.9354e-01, -9.9971e-01, -9.6816e-01,\n",
       "         -9.9997e-01, -2.1859e-01,  1.8247e-01, -9.9995e-01,  7.9963e-01,\n",
       "          9.9994e-01, -4.0968e-01,  8.2435e-01, -9.9908e-01, -1.5530e-01,\n",
       "         -8.2187e-02, -9.1650e-01,  3.0272e-01, -9.9983e-01, -1.4548e-01,\n",
       "         -9.9951e-01,  9.9255e-01, -9.9996e-01,  9.9475e-01,  9.9683e-01,\n",
       "         -2.7449e-01,  2.7295e-01,  1.5257e-01, -6.3403e-01, -9.9996e-01,\n",
       "         -3.0568e-01, -9.9980e-01, -9.9918e-01, -5.8187e-01,  9.9992e-01,\n",
       "          9.1799e-01,  1.4655e-02,  9.2762e-01, -9.9728e-01,  4.1391e-01,\n",
       "          1.7662e-01,  9.7649e-01,  9.9998e-01, -9.9898e-01, -9.7490e-01,\n",
       "          9.9885e-01, -9.9938e-01, -9.4023e-01,  9.9998e-01,  9.1235e-01,\n",
       "          9.9992e-01,  6.7249e-02, -9.9385e-01,  3.2546e-02,  1.0935e-01,\n",
       "          9.9450e-01,  3.1067e-01, -1.0228e-01,  9.9977e-01,  3.0725e-01,\n",
       "          2.0003e-01,  4.6749e-01,  9.6008e-01, -1.2211e-01, -1.6212e-01,\n",
       "          9.8491e-01, -7.1930e-01, -9.6814e-01, -9.9961e-01,  6.6864e-02,\n",
       "         -5.6956e-01, -1.8984e-01, -3.2760e-01, -7.7829e-01,  9.9996e-01,\n",
       "         -9.9180e-01,  8.8793e-01, -9.9997e-01, -9.9998e-01, -8.5503e-02,\n",
       "          2.8607e-02,  9.9970e-01,  7.5089e-02, -9.9526e-01,  1.3142e-01,\n",
       "         -9.9015e-01,  9.8621e-01, -9.9428e-01,  9.2386e-01, -3.7674e-01,\n",
       "         -1.7093e-02,  9.9960e-01,  9.9978e-01, -1.1326e-01, -9.9483e-01,\n",
       "         -9.9515e-01,  4.0367e-01, -9.5862e-01,  9.9414e-01, -2.3937e-01,\n",
       "         -3.8136e-01, -2.0301e-01,  1.0040e-01, -9.9943e-01, -9.9941e-01,\n",
       "          1.3978e-01,  9.7874e-01, -9.9971e-01, -8.8540e-01, -9.7292e-01,\n",
       "          9.9141e-01,  9.9984e-01,  1.0000e+00, -6.8363e-03,  3.7714e-01,\n",
       "         -9.0943e-01, -9.9568e-01,  7.1725e-01,  9.0880e-01,  9.9986e-01,\n",
       "          9.8703e-01,  8.7563e-01,  7.1677e-02, -9.9818e-01,  9.3907e-01,\n",
       "          7.6365e-01, -3.8568e-01, -7.9037e-02, -8.2244e-01, -9.9989e-01,\n",
       "          9.9699e-01, -9.9831e-01, -9.9625e-01, -7.1042e-01, -9.9839e-01,\n",
       "          9.8429e-01,  9.5101e-01,  9.9997e-01,  8.1766e-01, -9.9968e-01,\n",
       "         -9.7697e-01,  1.7617e-02, -8.2376e-01, -9.9551e-01,  2.3933e-01,\n",
       "         -9.9999e-01,  1.2328e-01, -4.4231e-02, -6.7683e-01,  2.4894e-01,\n",
       "          5.3640e-01, -9.0721e-01,  9.9949e-01, -1.5660e-01,  9.1671e-01,\n",
       "         -9.6814e-01, -9.9751e-01,  2.9389e-02, -9.9995e-01,  8.9782e-01,\n",
       "          1.0000e+00, -4.2874e-01,  9.9922e-01, -2.4888e-01,  1.7700e-01,\n",
       "         -9.9967e-01, -1.0000e+00,  7.9657e-01,  9.9927e-01,  2.3648e-01,\n",
       "         -9.9970e-01, -1.5538e-01, -9.9977e-01, -5.0166e-02,  8.0954e-01,\n",
       "          9.9258e-01, -1.0000e+00,  9.9891e-01,  3.8670e-01,  2.0655e-01,\n",
       "          9.6250e-01, -9.9999e-01, -9.0590e-01, -9.7748e-01,  9.9453e-01,\n",
       "         -1.0000e+00,  9.9694e-01, -7.3021e-01,  2.0993e-01,  5.4693e-02,\n",
       "          9.5398e-01, -9.9422e-01, -6.1103e-01,  9.3439e-01,  9.9298e-01,\n",
       "         -3.1632e-01,  8.7301e-01, -2.4111e-01]], grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained('hfl/rbt3')\n",
    "\n",
    "output = model(**inputs)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebdbcef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 17, 768])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1046126e",
   "metadata": {},
   "source": [
    "## Model calling with model head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b108309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee2e903c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at hfl/rbt3 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[0.0217, 0.1235]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clz_model = AutoModelForSequenceClassification.from_pretrained('hfl/rbt3', num_labels=2)\n",
    "clz_model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ebd5e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clz_model.config.num_labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
